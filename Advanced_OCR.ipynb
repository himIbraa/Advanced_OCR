{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF to PNG Image Converter\n",
    "\n",
    "A Python utility that batch converts PDF files into high-quality PNG images. Each page of every PDF is extracted and saved as a separate image file, organized by PDF name.\n",
    "\n",
    "**Features:**\n",
    "- üîÑ Batch process multiple PDFs\n",
    "- üìÅ Auto-organized output folders\n",
    "- üìä Configurable 200 DPI quality\n",
    "- üìù Detailed logging with progress\n",
    "- ‚ö†Ô∏è Robust error handling\n",
    "\n",
    "**Usage:** Place PDFs in `./PDF/` folder, run script, find images in `./media/{pdf_name}/`\n",
    "\n",
    "**Setup:**\n",
    "```bash\n",
    "pip install pdf2image\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from pdf2image import convert_from_path\n",
    "import logging\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# BASIC CONFIGURATION\n",
    "# ------------------------------------------------------------\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "\n",
    "PDF_DIR = Path(\"./PDF\")       # Folder containing PDFs\n",
    "MEDIA_ROOT = Path(\"./media\")  # Folder to save extracted images\n",
    "\n",
    "# Ensure media folder exists\n",
    "MEDIA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# FUNCTION: Convert one PDF to PNG images\n",
    "# ------------------------------------------------------------\n",
    "def process_pdf_extract_images(pdf_path: Path) -> bool:\n",
    "    \"\"\"Convert all pages of a PDF to PNG images in a separate folder.\"\"\"\n",
    "    logging.info(f\"üìÑ Received file: {pdf_path.name}\")\n",
    "\n",
    "    # Folder to store output images (e.g., ./media/my_pdf/)\n",
    "    pdf_output_folder = MEDIA_ROOT / pdf_path.stem\n",
    "    pdf_output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        # Convert PDF to images\n",
    "        logging.info(f\"‚öôÔ∏è Converting '{pdf_path.name}' to images...\")\n",
    "        dpi = 200  # Good quality for OCR, not too heavy\n",
    "        fmt = \"png\"\n",
    "\n",
    "        images = convert_from_path(pdf_path, dpi=dpi)\n",
    "        if not images:\n",
    "            raise FileNotFoundError(\"‚ùå No images were created from the PDF.\")\n",
    "\n",
    "        for i, image in enumerate(images, start=1):\n",
    "            image_path = pdf_output_folder / f\"page_{i}.png\"\n",
    "            image.save(image_path, fmt.upper())\n",
    "            logging.info(f\"‚úÖ Saved image: {image_path}\")\n",
    "\n",
    "        logging.info(f\"üéâ All {len(images)} pages extracted for '{pdf_path.name}'\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"‚ùå Error processing '{pdf_path.name}': {str(e)}\", exc_info=True)\n",
    "        return False\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# MAIN LOOP: Process all PDFs in ./PDF/\n",
    "# ------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    if not PDF_DIR.exists():\n",
    "        logging.error(f\"‚ùå The folder '{PDF_DIR}' does not exist.\")\n",
    "        exit(1)\n",
    "\n",
    "    pdf_files = sorted(PDF_DIR.glob(\"*.pdf\"))\n",
    "    if not pdf_files:\n",
    "        logging.warning(f\"‚ö†Ô∏è No PDF files found in '{PDF_DIR}'\")\n",
    "        exit(0)\n",
    "\n",
    "    logging.info(f\"üìÇ Found {len(pdf_files)} PDF file(s) to process...\")\n",
    "\n",
    "    for idx, pdf_file in enumerate(pdf_files, start=1):\n",
    "        logging.info(f\"\\n{'='*60}\\nProcessing {idx}/{len(pdf_files)}: {pdf_file.name}\")\n",
    "        success = process_pdf_extract_images(pdf_file)\n",
    "\n",
    "        if success:\n",
    "            logging.info(f\"‚úÖ Finished: {pdf_file.name}\")\n",
    "        else:\n",
    "            logging.warning(f\"‚ö†Ô∏è Failed: {pdf_file.name}\")\n",
    "\n",
    "    logging.info(\"\\nüèÅ All PDFs processed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decree Image Processor\n",
    "\n",
    "Processes extracted PDF images from official journals by removing headers, cropping white borders, and splitting pages into left/right columns for OCR and document analysis.\n",
    "\n",
    "**Features:**\n",
    "- üéØ Automatic white border removal\n",
    "- üìã Configurable header removal (4.5% by default)\n",
    "- üìñ Split two-column pages into individual images\n",
    "- üîÑ Batch process entire image directories\n",
    "- üìä Preserves page numbering in filenames\n",
    "\n",
    "**Input:** Images from previous PDF converter script (`./media/{pdf_name}/`)  \n",
    "**Output:** Processed images in `./media/{pdf_name}_output/` with `_left` and `_right` suffixes\n",
    "\n",
    "**Setup:**\n",
    "```bash\n",
    "pip install opencv-python numpy\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "input_folder = r\"\\media\\\"\n",
    "output_folder = r\"\\media\\\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# üîß Adjust this value to control how much of the top is cropped (e.g., 0.03 = 3%, 0.05 = 5%)\n",
    "HEADER_RATIO = 0.045\n",
    "\n",
    "# === PROCESS EACH IMAGE ===\n",
    "image_paths = sorted(glob.glob(os.path.join(input_folder, \"*.png\")))\n",
    "if not image_paths:\n",
    "    print(f\"‚ö†Ô∏è No image files found in folder: {input_folder}\")\n",
    "else:\n",
    "    for file_path in image_paths:\n",
    "        page_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        img = cv2.imread(file_path)\n",
    "        if img is None:\n",
    "            print(f\"‚ùå Could not read image: {file_path}\")\n",
    "            continue\n",
    "\n",
    "        # --- Remove white borders ---\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        _, thresh = cv2.threshold(gray, 250, 255, cv2.THRESH_BINARY_INV)\n",
    "        coords = cv2.findNonZero(thresh)\n",
    "        if coords is None:\n",
    "            print(f\"‚ö†Ô∏è Skipping blank image: {file_path}\")\n",
    "            continue\n",
    "\n",
    "        x, y, w, h = cv2.boundingRect(coords)\n",
    "        cropped = img[y:y + h, x:x + w]\n",
    "\n",
    "        # --- Remove header by percentage ---\n",
    "        header_height = int(cropped.shape[0] * HEADER_RATIO)\n",
    "        cropped_no_header = cropped[header_height:, :]\n",
    "\n",
    "        # --- Split into left/right halves ---\n",
    "        height, width, _ = cropped_no_header.shape\n",
    "        mid = width // 2\n",
    "        left_half = cropped_no_header[:, :mid]\n",
    "        right_half = cropped_no_header[:, mid:]\n",
    "\n",
    "        # --- Save outputs ---\n",
    "        left_path = os.path.join(output_folder, f\"{page_name}_left.png\")\n",
    "        right_path = os.path.join(output_folder, f\"{page_name}_right.png\")\n",
    "        cv2.imwrite(left_path, left_half)\n",
    "        cv2.imwrite(right_path, right_half)\n",
    "\n",
    "        print(f\"‚úÖ Processed page {page_name}\")\n",
    "\n",
    "    print(\"\\nüéâ All pages processed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Vision OCR Processor\n",
    "\n",
    "Extracts text from processed decree images using Google Cloud Vision API with full support for Arabic right-to-left (RTL) text. Outputs both structured JSON and merged plain text files.\n",
    "\n",
    "**Features:**\n",
    "- üß† Google Cloud Vision API OCR\n",
    "- üåç Full Arabic RTL support with directional markers\n",
    "- üìÑ Batch process entire image folders\n",
    "- üíæ Dual output format (JSON + TXT)\n",
    "- ‚è±Ô∏è Rate-limited API calls (1 second delay)\n",
    "- üìù Comprehensive logging and error handling\n",
    "\n",
    "**Input:** Processed images from decree processor (`./media/{pdf_name}/`)  \n",
    "**Output:** \n",
    "- `{folder_name}.json` - Structured per-page OCR results\n",
    "- `{folder_name}.txt` - Merged Arabic text (RTL formatted)\n",
    "\n",
    "**Setup:**\n",
    "```bash\n",
    "pip install google-cloud-vision\n",
    "# 1. Create Google Cloud project & enable Vision API\n",
    "# 2. Download service account credentials as credentials.json\n",
    "# 3. Place credentials.json in script directory\n",
    "```\n",
    "\n",
    "**Configuration:**\n",
    "- Input folder: `./media/laws/` (modify `media_root` variable)\n",
    "- API rate limit: 1 second per image (adjust `time.sleep()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "from google.cloud import vision\n",
    "from pathlib import Path\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# BASIC CONFIGURATION\n",
    "# ------------------------------------------------------------\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "\n",
    "credentials_path = os.path.join(os.getcwd(), \"credentials.json\")\n",
    "if not os.path.exists(credentials_path):\n",
    "    raise FileNotFoundError(\"‚ùå credentials.json not found in current folder\")\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = credentials_path\n",
    "\n",
    "# Initialize Vision API client\n",
    "try:\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    logging.info(\"‚úÖ Google Vision API client initialized\")\n",
    "except Exception as e:\n",
    "    logging.exception(\"‚ùå Failed to initialize Vision client\")\n",
    "    raise e\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# MAIN OCR FUNCTION\n",
    "# ------------------------------------------------------------\n",
    "def process_folder(folder_path: Path):\n",
    "    \"\"\"Process all images in one folder using Vision OCR (Arabic RTL).\"\"\"\n",
    "    logging.info(f\"\\nüìÇ Processing folder: {folder_path.name}\")\n",
    "\n",
    "    # Find all images\n",
    "    images = sorted(\n",
    "        [img for img in folder_path.iterdir() if img.suffix.lower() in [\".png\", \".jpg\", \".jpeg\"]],\n",
    "        key=lambda x: int(re.search(r'page_(\\d+)', x.name).group(1)) if re.search(r'page_(\\d+)', x.name) else float('inf')\n",
    "    )\n",
    "\n",
    "    if not images:\n",
    "        logging.warning(f\"‚ö†Ô∏è No images found in {folder_path}\")\n",
    "        return\n",
    "\n",
    "    ocr_results = {}\n",
    "\n",
    "    for idx, image_path in enumerate(images, 1):\n",
    "        logging.info(f\"üñºÔ∏è ({idx}/{len(images)}) {image_path.name}\")\n",
    "\n",
    "        try:\n",
    "            with io.open(image_path, \"rb\") as image_file:\n",
    "                content = image_file.read()\n",
    "\n",
    "            image = vision.Image(content=content)\n",
    "            response = client.document_text_detection(image=image)\n",
    "\n",
    "            if response.error.message:\n",
    "                logging.error(f\"‚ùå API Error for {image_path.name}: {response.error.message}\")\n",
    "                continue\n",
    "\n",
    "            full_text = response.full_text_annotation.text.strip()\n",
    "            if not full_text:\n",
    "                logging.warning(f\"‚ö†Ô∏è No text found in {image_path.name}\")\n",
    "                continue\n",
    "\n",
    "            # Force Arabic right-to-left display\n",
    "            rtl_marker = \"\\u202B\"   # Right-to-left embedding (RLE)\n",
    "            pop_marker = \"\\u202C\"   # Pop directional formatting\n",
    "            full_text_rtl = rtl_marker + full_text + pop_marker\n",
    "\n",
    "            ocr_results[image_path.name] = full_text_rtl\n",
    "            logging.info(f\"‚úÖ Extracted {len(full_text)} characters from {image_path.name}\")\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "        except Exception:\n",
    "            logging.exception(f\"‚ùå Error processing {image_path.name}\")\n",
    "\n",
    "    if not ocr_results:\n",
    "        logging.warning(f\"‚ö†Ô∏è No OCR results for {folder_path.name}\")\n",
    "        return\n",
    "\n",
    "    # Save results\n",
    "    json_path = folder_path / f\"{folder_path.name}.json\"\n",
    "    txt_path = folder_path / f\"{folder_path.name}.txt\"\n",
    "\n",
    "    try:\n",
    "        # Save JSON (for structured analysis)\n",
    "        with open(json_path, \"w\", encoding=\"utf-8\") as jf:\n",
    "            json.dump(ocr_results, jf, ensure_ascii=False, indent=4)\n",
    "        logging.info(f\"üíæ JSON saved: {json_path}\")\n",
    "\n",
    "        # Save merged text (Arabic right-to-left, no page headers)\n",
    "        with open(txt_path, \"w\", encoding=\"utf-8\") as tf:\n",
    "            for name in images:\n",
    "                if name.name in ocr_results:\n",
    "                    tf.write(ocr_results[name.name] + \"\\n\\n\")\n",
    "        logging.info(f\"üíæ Merged Arabic text saved: {txt_path}\")\n",
    "\n",
    "    except Exception:\n",
    "        logging.exception(f\"‚ùå Failed to save OCR results for {folder_path.name}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# MAIN LOOP ‚Äî PROCESS ALL SUBFOLDERS\n",
    "# ------------------------------------------------------------\n",
    "media_root = Path(\"./media/\")\n",
    "\n",
    "if not media_root.exists():\n",
    "    raise FileNotFoundError(\"‚ùå The './media' folder does not exist\")\n",
    "\n",
    "subfolders = [f for f in media_root.iterdir() if f.is_dir()]\n",
    "if not subfolders:\n",
    "    logging.warning(\"‚ö†Ô∏è No subfolders found in './media'. Nothing to process.\")\n",
    "else:\n",
    "    logging.info(f\"üìÅ Found {len(subfolders)} folder(s) to process under './media'\")\n",
    "\n",
    "for folder in subfolders:\n",
    "    process_folder(folder)\n",
    "\n",
    "logging.info(\"\\nüèÅ OCR extraction complete ‚Äî Arabic text written right-to-left and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Vision OCR Processor (Two-Column Optimized)\n",
    "\n",
    "Extracts text from two-column decree images using Google Cloud Vision API with intelligent right-before-left column ordering. Optimized for official journal documents with Arabic RTL support.\n",
    "\n",
    "**Features:**\n",
    "- üß† Google Cloud Vision API OCR\n",
    "- üìñ Intelligent two-column processing (right before left)\n",
    "- üåç Full Arabic right-to-left (RTL) support\n",
    "- üìÑ Batch process entire image folders\n",
    "- üíæ Dual output format (JSON + TXT)\n",
    "- ‚ö° Optimized rate-limiting (0.2s per image)\n",
    "- üìù Comprehensive logging and error handling\n",
    "\n",
    "**Input:** Two-column processed images from decree processor (`./media/laws/{folder}/page_*_left.png`, `page_*_right.png`)  \n",
    "**Output:** \n",
    "- `{folder_name}.json` - Structured per-image OCR results\n",
    "- `{folder_name}.txt` - Merged Arabic text (right‚Üíleft column order)\n",
    "\n",
    "**Setup:**\n",
    "```bash\n",
    "pip install google-cloud-vision\n",
    "# 1. Create Google Cloud project & enable Vision API\n",
    "# 2. Download service account credentials as credentials.json\n",
    "# 3. Place credentials.json in script directory\n",
    "```\n",
    "\n",
    "**Key Configuration:**\n",
    "- Input folder: `./media/laws/` (modify `media_root` variable)\n",
    "- API rate limit: 0.2 seconds per image (adjust `time.sleep(0.2)`)\n",
    "- Column order: Right pages processed before left pages\n",
    "\n",
    "**Processing Order Example:**\n",
    "```\n",
    "Input files:           Processing order:\n",
    "page_1_right.png  ‚Üí   1. page_1_right.png\n",
    "page_1_left.png   ‚Üí   2. page_1_left.png\n",
    "page_2_right.png  ‚Üí   3. page_2_right.png\n",
    "page_2_left.png   ‚Üí   4. page_2_left.png\n",
    "```\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "from google.cloud import vision\n",
    "from pathlib import Path\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# BASIC CONFIGURATION\n",
    "# ------------------------------------------------------------\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "\n",
    "credentials_path = os.path.join(os.getcwd(), \"credentials.json\")\n",
    "if not os.path.exists(credentials_path):\n",
    "    raise FileNotFoundError(\"‚ùå credentials.json not found in current folder\")\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = credentials_path\n",
    "\n",
    "# Initialize Vision API client\n",
    "try:\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    logging.info(\"‚úÖ Google Vision API client initialized\")\n",
    "except Exception as e:\n",
    "    logging.exception(\"‚ùå Failed to initialize Vision client\")\n",
    "    raise e\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# MAIN OCR FUNCTION\n",
    "# ------------------------------------------------------------\n",
    "def process_folder(folder_path: Path):\n",
    "    \"\"\"Process all images in one folder using Vision OCR (Arabic RTL, right before left).\"\"\"\n",
    "    logging.info(f\"\\nüìÇ Processing folder: {folder_path.name}\")\n",
    "\n",
    "    # Find all images\n",
    "    images = [img for img in folder_path.iterdir() if img.suffix.lower() in [\".png\", \".jpg\", \".jpeg\"]]\n",
    "    if not images:\n",
    "        logging.warning(f\"‚ö†Ô∏è No images found in {folder_path}\")\n",
    "        return\n",
    "\n",
    "    # Sort by page number, but ensure \"right\" comes before \"left\"\n",
    "    def sort_key(img):\n",
    "        match = re.search(r'page_(\\d+)', img.name)\n",
    "        page_num = int(match.group(1)) if match else float('inf')\n",
    "        # Ensure right page before left if same page number\n",
    "        right_first = 0 if \"right\" in img.name.lower() else 1\n",
    "        return (page_num, right_first)\n",
    "\n",
    "    images.sort(key=sort_key)\n",
    "\n",
    "    ocr_results = {}\n",
    "\n",
    "    for idx, image_path in enumerate(images, 1):\n",
    "        logging.info(f\"üñºÔ∏è ({idx}/{len(images)}) {image_path.name}\")\n",
    "\n",
    "        try:\n",
    "            with io.open(image_path, \"rb\") as image_file:\n",
    "                content = image_file.read()\n",
    "\n",
    "            image = vision.Image(content=content)\n",
    "            response = client.document_text_detection(image=image)\n",
    "\n",
    "            if response.error.message:\n",
    "                logging.error(f\"‚ùå API Error for {image_path.name}: {response.error.message}\")\n",
    "                continue\n",
    "\n",
    "            full_text = response.full_text_annotation.text.strip()\n",
    "            if not full_text:\n",
    "                logging.warning(f\"‚ö†Ô∏è No text found in {image_path.name}\")\n",
    "                continue\n",
    "\n",
    "            # Force right-to-left display for Arabic\n",
    "            rtl_marker = \"\\u202B\"   # Right-to-left embedding\n",
    "            pop_marker = \"\\u202C\"   # Pop directional formatting\n",
    "            full_text_rtl = rtl_marker + full_text + pop_marker\n",
    "\n",
    "            ocr_results[image_path.name] = full_text_rtl\n",
    "            logging.info(f\"‚úÖ Extracted {len(full_text)} characters from {image_path.name}\")\n",
    "\n",
    "            # Reduce delay ‚Äî you can set to 0 if you trust API limits\n",
    "            time.sleep(0.2)\n",
    "\n",
    "        except Exception:\n",
    "            logging.exception(f\"‚ùå Error processing {image_path.name}\")\n",
    "\n",
    "    if not ocr_results:\n",
    "        logging.warning(f\"‚ö†Ô∏è No OCR results for {folder_path.name}\")\n",
    "        return\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # SAVE RESULTS\n",
    "    # ------------------------------------------------------------\n",
    "    json_path = folder_path / f\"{folder_path.name}.json\"\n",
    "    txt_path = folder_path / f\"{folder_path.name}.txt\"\n",
    "\n",
    "    try:\n",
    "        # Save structured data (JSON)\n",
    "        with open(json_path, \"w\", encoding=\"utf-8\") as jf:\n",
    "            json.dump(ocr_results, jf, ensure_ascii=False, indent=4)\n",
    "        logging.info(f\"üíæ JSON saved: {json_path}\")\n",
    "\n",
    "        # Merge all text (no page headers, right before left)\n",
    "        with open(txt_path, \"w\", encoding=\"utf-8\") as tf:\n",
    "            for name in images:\n",
    "                if name.name in ocr_results:\n",
    "                    tf.write(ocr_results[name.name] + \"\\n\\n\")\n",
    "        logging.info(f\"üíæ Merged text saved: {txt_path}\")\n",
    "\n",
    "    except Exception:\n",
    "        logging.exception(f\"‚ùå Failed to save OCR results for {folder_path.name}\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# MAIN LOOP ‚Äî PROCESS ALL SUBFOLDERS\n",
    "# ------------------------------------------------------------\n",
    "media_root = Path(\"./media/\")\n",
    "\n",
    "if not media_root.exists():\n",
    "    raise FileNotFoundError(\"‚ùå The './media/laws' folder does not exist\")\n",
    "\n",
    "subfolders = [f for f in media_root.iterdir() if f.is_dir()]\n",
    "if not subfolders:\n",
    "    logging.warning(\"‚ö†Ô∏è No subfolders found in './media/laws'. Nothing to process.\")\n",
    "else:\n",
    "    logging.info(f\"üìÅ Found {len(subfolders)} folder(s) to process under './media/laws'\")\n",
    "\n",
    "for folder in subfolders:\n",
    "    process_folder(folder)\n",
    "\n",
    "logging.info(\"\\nüèÅ OCR extraction complete ‚Äî Arabic text saved right-to-left and read right-before-left.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
